# PRP-007: Memory Search & Specialized Retrieval Tools

## Description
Implement comprehensive memory search with semantic search (vector embeddings), category filters, and specialized retrieval tools for common use cases (friends summary, panic attacks, interests, etc.).

## Requirements

### Vector Search (Semantic)
- **pgvector Extension**: PostgreSQL vector similarity search
- **Embeddings Model**: sentence-transformers (all-MiniLM-L6-v2) or OpenAI
- **Embedding Storage**: 384-dimension vectors in PostgreSQL
- **Similarity Search**: Find memories by meaning, not just keywords
- **Hybrid Search**: Combine vector search with category/importance filters

### Specialized Tools
Based on common use cases, provide fast-access tools:
- `get_all_friends` - Summary of all person memories
- `get_panic_attacks` - All emotion:panic memories
- `get_interests` - All interest category memories
- `get_events` - Recent event memories
- `search_by_person` - All memories mentioning specific person
- `search_by_emotion` - Memories with specific emotional signals
- `search_across_versions` - Search all memory versions

## Database Schema Updates

### Add vector column to Memory
```python
from pgvector.sqlalchemy import Vector

class Memory(Base):
    # ... existing fields ...

    # NEW: Vector embedding for semantic search
    embedding: Mapped[Vector] = mapped_column(Vector(384), nullable=True)
```

### Migration
```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Add embedding column
ALTER TABLE memories ADD COLUMN embedding vector(384);

-- Create index for vector similarity search
CREATE INDEX memories_embedding_idx ON memories USING ivfflat (embedding vector_cosine_ops);
```

## Memory Service Extensions

```python
# services/memory_service.py (additions)

from sentence_transformers import SentenceTransformer

class MemoryService:
    def __init__(self):
        # ... existing init ...
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

    async def create_embedding(self, text: str) -> list[float]:
        """Generate embedding vector for text."""
        return self.embedding_model.encode(text).tolist()

    async def semantic_search(
        self,
        query: str,
        categories: list[str] = None,
        min_importance: int = 0,
        limit: int = 10
    ) -> list[dict]:
        """Search memories by semantic similarity."""

        # Generate query embedding
        query_embedding = await self.create_embedding(query)

        # Build query
        stmt = select(Memory)

        # Filter by categories if provided
        if categories:
            stmt = stmt.join(Memory.categories).where(
                Category.name.in_(categories)
            )

        # Filter by importance
        stmt = stmt.where(Memory.importance >= min_importance)

        # Order by similarity (cosine distance)
        stmt = stmt.order_by(
            Memory.embedding.cosine_distance(query_embedding)
        ).limit(limit)

        results = await db.execute(stmt)

        return [
            {
                "id": m.id,
                "simple_content": m.simple_content,
                "importance": m.importance,
                "categories": [c.name for c in m.categories]
            }
            for m in results.scalars().all()
        ]

    async def get_all_friends(self) -> list[dict]:
        """Get summary of all person-category memories."""

        stmt = select(Memory).join(Memory.categories).where(
            Category.name == "person"
        ).order_by(Memory.importance.desc())

        memories = await db.execute(stmt)

        return [
            {
                "id": m.id,
                "name": self._extract_person_name(m.simple_content),
                "summary": m.simple_content,
                "importance": m.importance
            }
            for m in memories.scalars().all()
        ]

    async def get_panic_attacks(self) -> list[dict]:
        """Get all emotion:panic memories."""

        stmt = select(Memory).join(Memory.categories).where(
            Category.name == "emotion"
        ).where(
            Memory.simple_content.ilike("%panic%")
        ).order_by(Memory.created_at.desc())

        memories = await db.execute(stmt)

        return [
            {
                "id": m.id,
                "date": m.created_at.date().isoformat(),
                "summary": m.simple_content,
                "importance": m.importance
            }
            for m in memories.scalars().all()
        ]

    async def get_interests(self) -> list[dict]:
        """Get all interest category memories."""

        stmt = select(Memory).join(Memory.categories).where(
            Category.name == "interest"
        ).order_by(Memory.importance.desc())

        memories = await db.execute(stmt)

        return [
            {
                "id": m.id,
                "interest": self._extract_interest_name(m.simple_content),
                "summary": m.simple_content,
                "importance": m.importance
            }
            for m in memories.scalars().all()
        ]

    async def search_by_person(self, person_name: str) -> list[dict]:
        """Find all memories mentioning a specific person."""

        # Use semantic search for better matching
        results = await self.semantic_search(
            query=f"memories about {person_name}",
            limit=50
        )

        # Filter by name mention
        return [
            r for r in results
            if person_name.lower() in r["simple_content"].lower()
        ]

    async def search_by_emotion(self, emotion: str) -> list[dict]:
        """Find memories with specific emotional signal."""

        return await self.semantic_search(
            query=f"{emotion} feeling emotion",
            categories=["emotion"],
            limit=20
        )

    async def search_across_versions(
        self,
        query: str,
        limit: int = 10
    ) -> list[dict]:
        """Search across all memory versions."""

        query_embedding = await self.create_embedding(query)

        # Search all memories (including old versions)
        stmt = select(Memory).order_by(
            Memory.embedding.cosine_distance(query_embedding)
        ).limit(limit)

        memories = await db.execute(stmt)

        return [
            {
                "id": m.id,
                "version": m.version,
                "simple_content": m.simple_content,
                "importance": m.importance,
                "created_at": m.created_at.isoformat()
            }
            for m in memories.scalars().all()
        ]

    def _extract_person_name(self, content: str) -> str:
        """Extract person name from memory content."""
        # Simple extraction - can be improved with NLP
        lines = content.split('\n')
        for line in lines:
            if 'name:' in line.lower():
                return line.split(':', 1)[1].strip()
        return "Unknown"

    def _extract_interest_name(self, content: str) -> str:
        """Extract interest name from memory content."""
        lines = content.split('\n')
        for line in lines:
            if 'interest:' in line.lower() or 'hobby:' in line.lower():
                return line.split(':', 1)[1].strip()
        return content[:50]  # First 50 chars as fallback
```

## Agent Tools

### Tool: semantic_search
```python
{
    "type": "function",
    "function": {
        "name": "semantic_search",
        "description": "Search memories by meaning, not just keywords. Finds conceptually similar memories.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "What to search for (natural language)"},
                "categories": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Filter by categories"
                },
                "min_importance": {"type": "integer"},
                "limit": {"type": "integer"}
            },
            "required": ["query"]
        }
    }
}
```

### Tool: get_all_friends
```python
{
    "type": "function",
    "function": {
        "name": "get_all_friends",
        "description": "Get summary of all friends and people we know",
        "parameters": {"type": "object", "properties": {}}
    }
}
```

### Tool: get_panic_attacks
```python
{
    "type": "function",
    "function": {
        "name": "get_panic_attacks",
        "description": "Get list of all panic attack memories, chronologically",
        "parameters": {"type": "object", "properties": {}}
    }
}
```

### Tool: get_interests
```python
{
    "type": "function",
    "function": {
        "name": "get_interests",
        "description": "Get list of all interests and hobbies",
        "parameters": {"type": "object", "properties": {}}
    }
}
```

### Tool: search_by_person
```python
{
    "type": "function",
    "function": {
        "name": "search_by_person",
        "description": "Find all memories about a specific person",
        "parameters": {
            "type": "object",
            "properties": {
                "person_name": {"type": "string", "description": "Name of the person to search for"}
            },
            "required": ["person_name"]
        }
    }
}
```

### Tool: search_by_emotion
```python
{
    "type": "function",
    "function": {
        "name": "search_by_emotion",
        "description": "Find memories with specific emotional signal (happy, sad, anxious, excited, etc.)",
        "parameters": {
            "type": "object",
            "properties": {
                "emotion": {"type": "string", "description": "Emotion to search for"}
            },
            "required": ["emotion"]
        }
    }
}
```

### Tool: search_across_versions
```python
{
    "type": "function",
    "function": {
        "name": "search_across_versions",
        "description": "Search all memory versions, including old versions that may have been updated",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string"}
            },
            "required": ["query"]
        }
    }
}
```

## Background Embedding Generation

When memories are created/updated, generate embeddings asynchronously:

```python
# services/memory_service.py

async def create_memory(self, full_content: str, ...) -> Memory:
    # ... existing logic ...

    # Generate embedding asynchronously
    asyncio.create_task(self._generate_and_store_embedding(memory.id, full_content))

    return memory

async def _generate_and_store_embedding(self, memory_id: int, content: str):
    """Background task to generate and store embedding."""
    try:
        embedding = await self.create_embedding(content)

        # Update memory with embedding
        memory = await db.get(Memory, memory_id)
        memory.embedding = embedding
        await db.commit()

        # Update cache
        await self.cache_memory(memory)
    except Exception as e:
        logging.error(f"Failed to generate embedding for memory {memory_id}: {e}")
```

## Dependencies
- pgvector>=0.2.0
- sentence-transformers>=2.2.0

## Cost Estimation
- Embeddings: Free (using sentence-transformers locally)
- OR OpenAI embeddings: $0.0001 per 1K tokens (~$0.0004 per memory)
- Recommendation: Use sentence-transformers (free, fast, good quality)

## Production Validation

### Vector Search
- [ ] pgvector extension enabled
- [ ] Embeddings generated for all memories
- [ ] Semantic search returns relevant results
- [ ] Performance acceptable (<500ms)

### Specialized Tools
- [ ] get_all_friends returns person memories
- [ ] get_panic_attacks returns emotion:panic memories
- [ ] get_interests returns interest memories
- [ ] search_by_person finds relevant memories
- [ ] search_by_emotion finds emotional memories

**Result**: ✅ PASS / ❌ FAIL

---

## Next PRPs
- **PRP-008**: Background Association Processing
- **PRP-009**: External Tools (Web search, cURL)
