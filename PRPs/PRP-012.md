# PRP-012: Analytics & Observability Integration

## Description
Implement comprehensive analytics and observability for dcmaidbot to track usage, performance, LLM interactions, user engagement, and system health. Use a combination of open-source tools optimized for self-hosted deployment and privacy-focused data collection.

## Requirements

### Analytics Stack
1. **LangSmith**: LLM tracing, cost tracking, and performance monitoring
2. **Prometheus**: Metrics collection (message counts, response times, errors)
3. **Grafana**: Visualization dashboards and alerting
4. **PostgreSQL**: Store custom analytics data (jokes reactions, user stats)

### Metrics to Track
- **Bot Performance**:
  - Message processing time
  - LLM response latency
  - API call success/failure rates
  - Memory/CPU usage

- **User Engagement**:
  - Active users (daily/weekly/monthly)
  - Message count per user
  - Command usage frequency
  - Chat activity heatmap

- **Joke Learning System**:
  - Jokes told vs reactions received
  - Joke success rate by type (setup_punchline, pun, transliteration)
  - Language-specific joke performance (ru vs en)
  - Context-based joke effectiveness

- **LLM Analytics** (via LangSmith):
  - Token usage per interaction
  - Cost per conversation
  - Model performance (GPT-4 vs GPT-3.5)
  - Prompt effectiveness
  - Error rates and types

- **Friend & Favor System**:
  - Friend interaction frequency
  - Favor request patterns
  - Tool usage by friends

- **Memory System**:
  - Memory creation/modification frequency
  - Memory match success rate
  - Admin intervention frequency

### Privacy & Compliance
- **No PII Collection**: Telegram IDs only (pseudonymous)
- **Opt-out Mechanism**: Users can disable analytics
- **Data Retention**: 90 days for raw events, 1 year for aggregated metrics
- **Admin-only Access**: Analytics dashboards restricted to admins from .env
- **GDPR Compliant**: Right to deletion, data export

## Definition of Ready (DOR)
- [ ] Research completed on analytics tools
- [ ] Analytics stack selected (LangSmith, Prometheus, Grafana)
- [ ] Database schema designed for custom analytics
- [ ] Privacy policy drafted for analytics collection
- [ ] Grafana dashboards designed (wireframes)
- [ ] Metrics naming conventions defined

## Definition of Done (DOD)
- [ ] LangSmith integration for LLM tracing
- [ ] Prometheus metrics exposed via `/metrics` endpoint
- [ ] Grafana dashboards configured with key metrics
- [ ] PostgreSQL analytics tables created
- [ ] Analytics service implemented (services/analytics_service.py)
- [ ] Privacy controls implemented (opt-out mechanism)
- [ ] Unit tests for analytics service
- [ ] E2E test for analytics pipeline
- [ ] Documentation for analytics setup
- [ ] Alerts configured in Grafana (high error rate, downtime)

## Progress

### Phase 1: Foundation
- [ ] Add dependencies (langsmith, prometheus_client, psycopg2-binary)
- [ ] Create analytics database schema (analytics_events, aggregated_stats)
- [ ] Implement analytics_service.py with event tracking
- [ ] Create Prometheus metrics registry

### Phase 2: LangSmith Integration
- [ ] Configure LangSmith API key in .env
- [ ] Wrap LLM calls with LangSmith tracing decorators
- [ ] Track joke generation prompts
- [ ] Track RAG retrieval prompts
- [ ] Monitor token usage and costs

### Phase 3: Prometheus Metrics
- [ ] Expose /metrics endpoint for Prometheus scraping
- [ ] Implement counters (messages_total, jokes_told_total)
- [ ] Implement gauges (active_users, memory_count)
- [ ] Implement histograms (message_processing_time_seconds)
- [ ] Implement summaries (llm_token_usage)

### Phase 4: Grafana Dashboards
- [ ] Create docker-compose.yml for Grafana + Prometheus
- [ ] Design dashboard: Bot Overview (messages, users, uptime)
- [ ] Design dashboard: Joke Performance (success rate by type/language)
- [ ] Design dashboard: LLM Analytics (costs, tokens, latency)
- [ ] Design dashboard: System Health (CPU, memory, errors)
- [ ] Configure alerts (error rate > 5%, downtime > 1min)

### Phase 5: Custom Analytics
- [ ] Create AnalyticsEvent model (event_type, user_id, metadata, timestamp)
- [ ] Create AggregatedStat model (metric_name, value, aggregation_period)
- [ ] Implement daily aggregation cron job
- [ ] Track joke reactions → joke_success table
- [ ] Track user engagement → user_activity table

### Phase 6: Privacy & Compliance
- [ ] Implement opt-out flag in User model (analytics_enabled)
- [ ] Create /analytics_optout command
- [ ] Implement data export for GDPR (JSON dump per user)
- [ ] Implement data deletion (90-day retention policy)
- [ ] Add analytics disclaimer to bot startup message

### Phase 7: Testing
- [ ] Unit test: track_event() method
- [ ] Unit test: Prometheus metrics registration
- [ ] Unit test: Data aggregation logic
- [ ] E2E test: Message → Analytics event → Prometheus metric
- [ ] E2E test: Opt-out mechanism
- [ ] Load test: 1000 events/second

## System Analysis Results (Nov 1, 2025)

### DOR Status: [DOR-NOT-MET]
**Missing Prerequisites:**
- No research completed on analytics tools integration
- Analytics stack not finalized (LangSmith vs alternatives)
- Database schema not designed for analytics
- Privacy policy not drafted for analytics collection
- Grafana dashboards not designed
- Metrics naming conventions not defined

### DOD Status: [DOD-NOT-STARTED]
**Implementation Analysis:**
- ❌ **LangSmith Integration**: No langsmith dependency or configuration
- ❌ **Prometheus Metrics**: No /metrics endpoint or metrics collection
- ❌ **Grafana Dashboards**: No visualization infrastructure
- ❌ **Analytics Service**: No services/analytics_service.py implemented
- ❌ **Database Schema**: No analytics_events or aggregated_stats tables
- ❌ **Privacy Controls**: No opt-out mechanism or GDPR compliance

**Evidence:**
- `requirements.txt`: No langsmith, prometheus_client dependencies
- `services/`: No analytics_service.py file found
- `models/`: No AnalyticsEvent or AggregatedStat models
- `handlers/`: No analytics endpoints or opt-out commands
- No /metrics endpoint in bot implementation
- No Grafana or Prometheus infrastructure found

### Current Analytics Status:
- ✅ **Basic Logging**: Standard Python logging implemented
- ✅ **Database Tracking**: Basic message and user tracking in models
- ❌ **Advanced Analytics**: No comprehensive analytics stack
- ❌ **Metrics Collection**: No Prometheus or external monitoring
- ❌ **LLM Observability**: No LangSmith or similar integration

### Blockers Identified:
1. **Analytics Stack**: Need to select and implement monitoring tools
2. **Dependencies**: Add analytics-related packages
3. **Database Schema**: Create analytics-specific tables
4. **Privacy Implementation**: Need GDPR compliance features
5. **Infrastructure**: Set up Grafana/Prometheus stack

### Recommendation:
PRP-012 requires complete implementation from scratch. No analytics infrastructure exists beyond basic logging.

## AGA Verification Results (Nov 1, 2025)

### [AGA-FAILED] - PRP-012: Analytics & Observability Integration

**Production Test Results:**
- ✅ Bot deployed and healthy: https://dcmaidbot.theedgestory.org
- ✅ Basic logging: Standard Python logging functional
- ❌ Metrics endpoint: No /metrics endpoint available
- ❌ Analytics service: No comprehensive monitoring implemented
- ❌ Observability stack: No LangSmith, Prometheus, or Grafana

**Local Testing:**
- Analytics Dependencies: No langsmith or prometheus_client in requirements.txt
- Metrics Collection: No metrics framework implemented
- Dashboard Infrastructure: No Grafana or visualization tools
- Privacy Controls: No opt-out mechanisms or GDPR compliance

**Infrastructure Analysis:**
**Current Implementation:**
1. ✅ **Basic Logging**: Python logging system operational
2. ✅ **Database Models**: Basic user and message tracking
3. ✅ **Health Monitoring**: Simple health endpoint available

**Missing Components:**
1. ❌ **LangSmith Integration**: No LLM observability or tracing
2. ❌ **Prometheus Metrics**: No /metrics endpoint or metric collection
3. ❌ **Grafana Dashboards**: No visualization infrastructure
4. ❌ **Analytics Service**: No services/analytics_service.py implementation
5. ❌ **Database Schema**: No analytics_events or aggregated_stats tables
6. ❌ **Privacy Controls**: No opt-out mechanisms or GDPR compliance
7. ❌ **Custom Metrics**: No business metrics tracking

**Monitoring Gap Analysis:**
**Performance Metrics Missing:**
- Message processing time
- LLM response latency
- API call success/failure rates
- Memory/CPU usage monitoring

**User Engagement Missing:**
- Active users tracking (daily/weekly/monthly)
- Message count per user
- Command usage frequency
- Chat activity heatmap

**Business Intelligence Missing:**
- Joke learning effectiveness
- Memory creation patterns
- Tool usage analytics
- Friend interaction frequency

**Privacy & Compliance Missing:**
- User opt-out mechanisms
- Data retention policies
- GDPR compliance features
- PII protection controls

**Dependencies Analysis:**
- Current: Basic logging and database tracking
- Required: langsmith, prometheus_client, grafana infrastructure
- Complexity: High - requires complete analytics stack implementation

**Architecture Requirements:**
- Metrics Collection: Prometheus integration with custom metrics
- Visualization: Grafana dashboards for system and business metrics
- LLM Observability: LangSmith for prompt engineering and cost tracking
- Privacy: GDPR-compliant data collection and retention policies

**Conclusion**: PRP-012 requires complete implementation from scratch. Current system has only basic logging; comprehensive analytics and observability stack needs to be designed and implemented. Comprehensive monitoring stack needs to be designed and implemented.

## Notes

### LangSmith Setup
```python
import os
from langsmith import Client

os.environ["LANGSMITH_API_KEY"] = os.getenv("LANGSMITH_API_KEY")
os.environ["LANGSMITH_TRACING"] = "true"

# Automatically traces all LangChain calls
```

### Prometheus Metrics Examples
```python
from prometheus_client import Counter, Histogram, Gauge

messages_total = Counter('dcmaidbot_messages_total', 'Total messages processed', ['chat_type', 'language'])
joke_reactions = Counter('dcmaidbot_joke_reactions_total', 'Joke reactions', ['joke_type', 'reaction_type'])
processing_time = Histogram('dcmaidbot_message_processing_seconds', 'Message processing time')
active_users = Gauge('dcmaidbot_active_users', 'Currently active users')
```

### Grafana Dashboard Panels
- **Bot Overview**:
  - Messages per hour (time series)
  - Active users (gauge)
  - Joke success rate (pie chart)
  - Top commands (bar chart)

- **Joke Performance**:
  - Reactions by joke type (stacked area)
  - Language preference (pie chart)
  - Context effectiveness (heatmap)

- **LLM Analytics**:
  - Token usage over time (area chart)
  - Cost per day (line chart)
  - Prompt latency (histogram)
  - Error rate (stat panel)

### Database Schema
```sql
CREATE TABLE analytics_events (
    id SERIAL PRIMARY KEY,
    event_type VARCHAR(100) NOT NULL,  -- 'message_sent', 'joke_told', 'llm_call', etc.
    user_id INTEGER REFERENCES users(id),
    chat_id BIGINT,
    metadata JSONB,  -- Flexible storage for event-specific data
    timestamp TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_analytics_events_type_time ON analytics_events(event_type, timestamp);

CREATE TABLE aggregated_stats (
    id SERIAL PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    metric_value FLOAT NOT NULL,
    aggregation_period VARCHAR(20),  -- 'hourly', 'daily', 'weekly'
    period_start TIMESTAMP NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### Privacy Configuration
```env
# Analytics (PRP-012)
LANGSMITH_API_KEY=your_langsmith_api_key
LANGSMITH_PROJECT_NAME=dcmaidbot
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
ANALYTICS_RETENTION_DAYS=90
```

## Alternatives Considered

### PostHog (Not Selected)
- **Pros**: All-in-one (analytics + feature flags + session replay)
- **Cons**: Heavy for bot use case, designed for web/mobile apps
- **Decision**: Too complex for Telegram bot, better suited for web apps

### Umami/Plausible (Not Selected)
- **Pros**: Simple, privacy-focused, lightweight
- **Cons**: Web analytics only, not suitable for bot/LLM tracking
- **Decision**: No LLM tracing, no custom events for jokes/memories

### Why LangSmith + Prometheus + Grafana?
- **LangSmith**: Industry standard for LLM observability, LangChain native
- **Prometheus**: De facto standard for metrics, Kubernetes-native
- **Grafana**: Most popular visualization tool, rich ecosystem
- **PostgreSQL**: Already in use, no additional infrastructure
- **Lightweight**: Only 3 services (LangSmith cloud, Prometheus, Grafana local)
- **Self-hosted**: Full control, no vendor lock-in (except LangSmith)

## Agent Comments
<!-- Add progress notes here as you work on this PRP -->
