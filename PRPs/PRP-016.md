# PRP-016: Animal Crossing Neighborhood Floor Continuity System

**Status**: ðŸ”„ **Active Implementation**
**Priority**: ðŸ”´ CRITICAL
**Assignee**: Agent
**Created**: 2025-11-02
**Updated**: 2025-11-02
**Branch**: friends-update

## ðŸŽ¯ Main Goal

Achieve seamless neighborhood floor continuity between connected locations using orthographic Animal Crossing style generation with proper inpainting for floor transitions and widget integration.

## progress


## ðŸ“ Files Working On

### Core Scripts
- `scripts/world_builder/*.py` - Main generation pipeline
- `static/index.html` and `static/index.js` for frontend application. existed one requre adjustments but as base ok, lets not double implementation and careful split html with js, and all layers/floors make real div with all widgets text content inside to keep clean SEO-friendly template, i suggest make `scripts/world_builder/viewer_builder.py` what will produce new `static/index.html` and `static/index.css` with fine tuned values, then `static/index.js` will focus on floor state switching (but with css overlay-transition animations) with widget class hover/click and canvas blending dynamic values for widgets. each widget should have own code in index.js AND `static/styles.css` WILL BE main style file we import in index.html template and use with all shared styles from here, lets index.css be responsible for only layer adjustments

### Configuration
- `static/world.json` - World configuration with detailed location descriptions, require extending

### Testing
- `tests/business/dod_validation/test_prp016_world_generation_llm_judge.py` - Complex tests to each pipeline step formal algorythm researched in THIS document. tests should compare expectations from this document steps of generation-expectation with visual llm comparison for each pipeline step. after all done we need aggregate all tmp file paths and judges detailed resolutions AND need return final judge llm with simple CoT thre steps cycle for confidence and reflection with spectial prompt, we need get MANY aspects and acceptance score from 0 to 100 AND THIS NOT WORKING IN CI! NOT WORKING FOR E2E PROD! ONLY MANUAL RUN THEN NEEDED!
- `tests/business/user_journeys/landing_visual_judge.py` - visual llm jusdge and world.json and prp comparison and resolution with three way acceptance score and different criterias, should use playwrite, screenshots, and make all actions and go through widget interations and scroll with e2e experience. for dev goes to dev instance in CI (should be deployed with kubectl to domain like dcmaidbot-dev.theedgestory.org and use local .env secrets to it as telegram bot token and provide exact same configuration with certificates like at dcmaidbot.theedgestory.org)
- ??? maybe more?

### Output
- `static/output/` - Generated base scenes and overlays
- `static/cache/` - Content-addressed cache system

## progress
signal | comment | time | role-name (model name)
[dp] | Foundation implementation - Created WorldService with terrain generation system, 7 terrain types with emoji representation, /generate_world and /world_info commands implemented. Basic world generation operational. | 2025-11-03 20:30 | Robo-Developer (Sonnet 4.5)

## dod

## dor

## plan
- [ ]

## pre-release checklist

## post-release checklist


## research results
viewer

Exhaustive, implementation-grade checklist. Copy steps verbatim. File paths are absolute relative to repo root. Verification is mandatory per step. Fallbacks provided where applicable.

0. repo layout (create exactly)
	â€¢	/static/index.html
	â€¢	/static/style.css                  â† global styles, HUD, typography, animations, modals
	â€¢	/static/index.css                 â† per-floor/layer positioning only
	â€¢	/static/index.js                  â† thin JS: floor state, audio triggers, dynamic text widgets
	â€¢	/static/world.json                â† source of truth
	â€¢	/static/audio/                    â† downloaded licensed audio
	â€¢	/static/img/                      â† generated base tiles + widget overlays
	â€¢	/static/output/                   â† optional stitched images
	â€¢	/static/cache/                    â† content-addressed cache (CACS)
	â€¢	/scripts/world_builder/viewer_builder.py
	â€¢	/scripts/world_builder/world_generator.py
	â€¢	/scripts/world_builder/utils.py
	â€¢	/tests/business/dod_validation/test_prp016_world_generation_llm_judge.py (manual-only)
	â€¢	/tests/business/user_journeys/landing_visual_judge.py
	â€¢	/.env with OPENAI_API_KEY, HF_API_KEY, LEONARDO_API_KEY, REPLICATE_API_KEY

Verify
	â€¢	tree static scripts tests | wc -l > 20
	â€¢	.env exists and contains four non-empty keys.

â¸»

1. world.json contract (viewer needs this shape)
	â€¢	Top-level keys:

{
  "meta": { "version": "0.1.0", "site_title": "dcmaidbot", "seed_policy": "strict" },
  "camera": { "mode": "isometric", "angle_deg": 45, "zoom": 1.0, "tile_px": 64, "palette": "16-bit" },
  "navigation": { "sequence": ["house_main","house_attach","garden","street","mall","mall2"] },
  "floors": [
    { "id": "floor1", "order": 1, "locations": ["house_main","garden","street"] },
    { "id": "floor2", "order": 2, "locations": ["house_attach","mall"] },
    { "id": "floor3", "order": 3, "locations": ["mall2"] }
  ],
  "locations": [
    {
      "id": "house_main",
      "floor": "floor1",
      "grid_rect": { "x": 0, "y": 0, "w": 25, "h": 25 },      // tile coords
      "prompt_base": "Lilit room, Helsinki references, top-down isometric 16-bit calm palette",
      "style_tokens": ["animal crossing", "SNES", "orthographic", "no shadows"],
      "img": { "base": "img/house_main/base.png" },
      "widgets": [
        {
          "id": "clock",
          "type": "digital_clock",
          "area_mask": "img/house_main/masks/clock.png",
          "alt": "digital clock showing current time",
          "states": [
            { "id": "idle",  "overlay": "img/house_main/overlays/clock_idle.png" }
          ],
          "audio": { "hover": "audio/sfx_hover.mp3", "click": "audio/sfx_click.mp3" },
          "seo_text": "Helsinki time and day."
        }
      ],
      "modals": [
        {
          "id": "changelog",
          "title": "Project Changelog",
          "markdown": "raw GitHub link and story markdown here...",
          "link_raw": "https://raw.githubusercontent.com/uz0/dcmaidbot/main/CHANGELOG.md"
        }
      ]
    }
  ]
}


	â€¢	No two locations share the same grid_rect on a floor.
	â€¢	All widgets have at least state idle.
	â€¢	Every referenced path exists or has a placeholder.

Verify
	â€¢	python - <<'PY'\nimport json,sys; j=json.load(open('static/world.json')); assert {'meta','camera','floors','locations'}<=j.keys(); assert all('widgets'in L for L in j['locations']); print('ok')\nPY â†’ ok.

â¸»

2. audio library (licensed)
	â€¢	Download ambient and UI SFX (keep from same library for timbre coherence):
	â€¢	Ambient candidates (choose one):
	â€¢	FASSounds â€“ Good Night â€“ Lofi Cozy Chill Music. Download MP3. License: Pixabay Content License (free to use, attribution recommended).  ï¿¼
	â€¢	Lofidreams â€“ Rainy Lofi City â€“ Lofi Music.  ï¿¼
	â€¢	UI SFX (hover/click):
	â€¢	UI Sounds Pack 2 Sound (5) (click/pop).  ï¿¼
	â€¢	UI Sounds Pack 2 Sound (8) (hover/rollover).  ï¿¼
	â€¢	Save as:
	â€¢	/static/audio/bgm_lofi.mp3
	â€¢	/static/audio/sfx_hover.mp3
	â€¢	/static/audio/sfx_click.mp3
	â€¢	Footer credit HTML:

Ambient: â€œGood Night â€“ Lofi Cozy Chill Musicâ€ by FASSounds (Pixabay). UI SFX: â€œUI Sounds Pack 2â€ (Pixabay).


	â€¢	Accessibility transcript: one paragraph describing ambience (SEO friendly).

Verify
	â€¢	Files exist and are < 3MB each.
	â€¢	ffprobe static/audio/*.mp3 shows sample rate 44.1k or 48k.

â¸»

3. style.css (global, HUD, animations, modals)
	â€¢	Base reset + fonts.
	â€¢	Sticky HUD at bottom:
	â€¢	.hud fixed bottom, 100% width, translucent, blur backdrop.
	â€¢	.hud a large hit area, [aria-current="true"] style.
	â€¢	Floor transition classes:
	â€¢	.floor-transition-out â†’ transform: scale(.90); filter: blur(2px); transition: 450ms ease;
	â€¢	.floor-transition-in  â†’ transform: none; filter: none; transition: 450ms ease;
	â€¢	Reduced motion:

@media (prefers-reduced-motion: reduce){
  *{animation:none!important; transition:none!important}
}

Guidance: MDN prefers-reduced-motion.  ï¿¼

	â€¢	CSS-only modal (accessible pattern uses :target to open; ARIA role/labels in HTML):
	â€¢	.modal{display:none} + :target.modal{display:block}
	â€¢	Focus management fallback documented (use WAI APG for modal roles).  ï¿¼

Verify
	â€¢	Toggle a test class in devtools; animation applies.
	â€¢	OS reduced motion on â†’ no animations.

â¸»

4. index.css (layering only)
	â€¢	.floor blocks stacked with position: relative.
	â€¢	.location absolutely placed inside floor container using grid_rect to compute left/top/width/height in viewer_builder.py.
	â€¢	.widgets [data-widget] absolutely positioned children.
	â€¢	.is-active floor visible; others visibility:hidden; pointer-events:none.

Verify
	â€¢	Manually toggle .is-active on a floor; only one floor visible.

â¸»

5. index.html (SEO-first; no JS required to read)
	â€¢	<head>:
	â€¢	<title> from meta.site_title
	â€¢	<meta name="description"> from synopsis
	â€¢	link rel="stylesheet" href="/static/style.css"
	â€¢	link rel="stylesheet" href="/static/index.css"
	â€¢	JSON-LD breadcrumb for floors/locations (optional)
	â€¢	<header>:
	â€¢	<h1> site title
	â€¢	<nav class="hud" aria-label="Floors"> with <a href="#floor1" data-sfx="hover click">Floor 1</a> per floor. aria-current="true" on active.
	â€¢	<main>:
	â€¢	For each floor F:
	â€¢	<section id="F" class="floor"> <h2>Floor N</h2> ... </section>
	â€¢	Each location:

<article id="loc-<id>" class="location">
  <h3>Location: <id></h3>
  <figure>
    <img src="/static/img/<id>/base.png" alt="<alt from prompt_base>">
    <figcaption>SEO story from world.json</figcaption>
  </figure>
  <div class="widgets">
    <!-- overlays as <img> for SEO visibility plus data attributes -->
    <img data-widget="clock" data-state="idle" alt="digital clock" src="/static/img/<id>/overlays/clock_idle.png">
    <!-- modal triggers -->
    <a href="#modal-<id>-changelog" class="btn">Changelog</a>
  </div>
</article>


	â€¢	Modals (CSS :target):

<section id="modal-<id>-changelog" class="modal" role="dialog" aria-modal="true" aria-labelledby="m-title-<id>">
  <h2 id="m-title-<id>">Changelog</h2>
  <div class="modal-body"><!-- markdown injected to HTML by viewer_builder.py --></div>
  <a class="modal-close" href="#close">Close</a>
</section>


	â€¢	<footer>:
	â€¢	credits, transcripts, sitemap link.

Verify
	â€¢	Open static/index.html in browser: content visible with JS disabled.
	â€¢	Heading order: h1â†’h2â†’h3 with no skips.

â¸»

6. index.js (thin)
	â€¢	On DOMContentLoaded:
	â€¢	Resolve location.hash â†’ set active floor (toggle .is-active), apply .floor-transition-in/out classes on switch.
	â€¢	Add click handlers on HUD links: prevent default, animate out current, after 450ms set hash, animate in target.
	â€¢	Audio:

const bgm=document.getElementById('bgm');
const hover=new Audio('/static/audio/sfx_hover.mp3');
const click=new Audio('/static/audio/sfx_click.mp3');
let audioArmed=false;
window.addEventListener('pointerdown',()=>{ if(!audioArmed){ bgm.play().catch(()=>{}); audioArmed=true; }}, {once:true});
document.querySelectorAll('[data-sfx]').forEach(el=>{
  if(el.dataset.sfx.includes('hover')) el.addEventListener('mouseenter',()=>hover.play().catch(()=>{}));
  if(el.dataset.sfx.includes('click')) el.addEventListener('click',()=>click.play().catch(()=>{}));
});


	â€¢	Dynamic text widgets (clock):

setInterval(()=>{
  document.querySelectorAll('[data-widget="clock"]').forEach(el=>{
    const d=new Date(); el.textContent = d.toLocaleTimeString([], {hour:'2-digit', minute:'2-digit'});
  });
},1000);


	â€¢	Add <audio id="bgm" src="/static/audio/bgm_lofi.mp3" loop preload="auto"></audio> to HTML.

Verify
	â€¢	First pointerdown starts BGM (browser policy).
	â€¢	Hover/click sounds trigger (currentTime progresses).

â¸»

7. viewer_builder.py (generate HTML/CSS from world.json)
	â€¢	CLI:

python scripts/world_builder/viewer_builder.py \
  --json static/world.json \
  --out static \
  --emit-sitemap 1


	â€¢	Responsibilities:
	â€¢	Validate schema (camera/floors/locations/widgets).
	â€¢	Convert Markdown in modals[].markdown to HTML.
	â€¢	Compute absolute positioning in index.css from grid_rect â†’ px:

left = x * camera.tile_px
top  = y * (camera.tile_px * 0.5)   # if isometric staggering; else 1.0 for top-down
width = w * camera.tile_px
height = h * camera.tile_px


	â€¢	Emit index.html, only writing style.css/index.css if missing.
	â€¢	Generate sitemap.xml and robots.txt referencing sitemap.

Verify
	â€¢	Rebuild â†’ idempotent (same files if no changes).
	â€¢	W3C validator passes. Lighthouse SEO â‰¥ 90.

â¸»

8. visual e2e (Playwright)
	â€¢	playwright install chromium
	â€¢	tests/business/user_journeys/landing_visual_judge.py does:
	â€¢	open file://.../static/index.html
	â€¢	await expect(page.locator('#floor1')).toBeVisible()
	â€¢	take screenshot per floor after clicking HUD; use toHaveScreenshot() with per-floor masks for dynamic text.  ï¿¼
	â€¢	Compare to baselines committed in repo.

Verify
	â€¢	CI run produces zero screenshot diffs.

â¸»

9. accessibility
	â€¢	Use WAI APG modal guidance: roles, labelledby, describedby, focus intent documented (CSS :target minimal).  ï¿¼
	â€¢	Reduced-motion supported.  ï¿¼

Verify
	â€¢	Lighthouse A11y â‰¥ 90.

â¸»

10. SEO
	â€¢	Title/description per page.
	â€¢	One h1.
	â€¢	Alt text meaningful (not keyword spam).
	â€¢	Sitemap present.

Verify
	â€¢	Manual SERP snippet preview (length, truncation).

â¸»

11. failure modes
	â€¢	If a floor anchor has no generated images, viewer displays blurred previous-floor placeholder (CSS only: apply filter: blur(2px) and white overlay).
	â€¢	If audio blocked, viewer continues without sound.

Verify
	â€¢	Simulate missing /static/img/<id>/base.png: placeholder visible.

â¸»

12. links used
	â€¢	SynCity paper (tile context + blend).  ï¿¼
	â€¢	Diffusers inpaint, pipelines.  ï¿¼
	â€¢	ControlNet canny/depth + multi-ControlNet.  ï¿¼
	â€¢	MDN prefers-reduced-motion.  ï¿¼
	â€¢	Playwright visual snapshots/screenshots.  ï¿¼
	â€¢	Accessible modal guidance.  ï¿¼
	â€¢	Pixel-Art XL LoRA (isometric-friendly).  ï¿¼
	â€¢	Pixabay audio pages.  ï¿¼

â¸»

tiles

Deterministic SynCity-style world generation. Step-by-step algorithm, interfaces, and code-level explanations for /scripts/world_builder/*.py.

0. deterministic runtime
	â€¢	Fix seeds and backends:
	â€¢	Set PYTORCH_ENABLE_MPS_FALLBACK=1 on macOS.
	â€¢	Use CPU or MPS for reproducibility; document tolerance (SSIM â‰¥ 0.99 outside masks).
	â€¢	Save metadata per output: {prompt, negative, seed, model_id, scheduler, controlnets, mask_hash, base_hash, tile_rect, floor, location_id}.

Verify
	â€¢	Re-run with same inputs â†’ identical CACS key, same file path.

â¸»

1. pipeline selection + fallbacks

Plan A (preferred)
	â€¢	HF Diffusers StableDiffusionInpaintPipeline with Pixel-Art XL LoRA; optional ControlNet canny/depth to lock geometry. Seeds enforced via torch.Generator.  ï¿¼

Plan B
	â€¢	Leonardo SDXL Inpaint with explicit seed; then SD inpaint ring-blend 8px on tile borders to remove seams.

Plan C
	â€¢	OpenAI DALLÂ·E 3 for initial composition (non-deterministic) â†’ SD inpaint finalize with seed. (Label determinism: [Unverified].)

Switching rule
	â€¢	If CLIP-caption or LLM-vision fails semantic check, or border SSIM < 0.98, escalate Aâ†’Bâ†’C.

â¸»

2. file outputs and cache keys
	â€¢	Output per location:
	â€¢	static/img/<loc>/base.png
	â€¢	static/img/<loc>/overlays/<widget>_<state>.png (transparent)
	â€¢	static/img/<loc>/masks/<name>.png
	â€¢	static/img/<loc>/meta/*.json
	â€¢	Cache key:

sha256(
  model_id + scheduler + prompt + negative +
  seed + mask_hash + base_hash + controlnet_flags
)


	â€¢	On hit â†’ skip generation.

Verify
	â€¢	Delete one overlay â†’ only that overlay regenerates.

â¸»

3. world_generator.py interfaces

- scripts/world_builder/world_generator.py
from pathlib import Path
from .utils import (
    load_world, ensure_dirs, hash_bytes, ssim,
    build_prompt, load_mask, compose_base, blur_overlay
)

def main(json_path:str, out_dir:str, cache_dir:str,
         provider:str="planA", seed:int=424242)->int: ...

CLI

python scripts/world_builder/world_generator.py \
  --json static/world.json \
  --out static/img \
  --cache static/cache \
  --provider planA \
  --seed 424242

Process (per floor, leftâ†’right by navigation sequence)
	1.	compose_base_for_tile(loc):
	â€¢	If first floor first tile: start from uniform grey slab (SynCity practice) matching camera frame.  ï¿¼
	â€¢	Else: rasterize context canvas by drawing already-generated neighbor tiles (N,W,NW,NE,SW etc.) into a larger canvas; cut the region that includes the target tile + 8px border.
	â€¢	If higher floor and tile not yet generated on lower floor: use blurred previous floor base made by blur_overlay(prev_floor_image, radius=2, alpha=0.30) (placeholder context).
	2.	mask_current_tile(loc):
	â€¢	Binary mask for grid_rect (default). If location defines extra_masks (doors spanning edges etc.) union them.
	3.	prompt_current_tile(loc):
	â€¢	prompt = build_prompt(camera, style_tokens, loc.prompt_base, global_tokens)
	â€¢	Negative tokens to suppress shadows, perspective, light direction.
	4.	generate_tile_inpaint(base, mask, prompt, provider, seed):
	â€¢	Plan A: diffusers inpaint with Pixel-Art XL LoRA; if geometry must be locked, compute canny or depth map on base, pass ControlNets with controlnet_conditioning_scale âˆˆ [0.6,0.9].  ï¿¼
	â€¢	Save base.png and meta.json. Keep seed fixed per location id.
	5.	widgets for tile(loc):
	â€¢	For each widget:
	â€¢	Idle: inpaint(base.png, mask=widget.mask, prompt=widget.idle_prompt) â†’ overlays/<widget>_idle.png
	â€¢	States: for each state s: inpaint(prev=idle_composite, mask=s.mask or widget.mask, prompt=s.prompt) â†’ overlays/<widget>_<s>.png
	â€¢	Only pixels within mask are allowed to change (verify).
	6.	edge-blend guard:
	â€¢	Compute SSIM on a 6â€“8px ring at tile borders vs neighbors; if < 0.98, run ring inpaint: create mask as only the border ring, prompt â€œpreserve continuity with adjacent tilesâ€, re-inpaint once.

Verify (per tile)
	â€¢	Outside mask unchanged vs base (pixel exact).
	â€¢	Border SSIM â‰¥ 0.98 (after ring fix if needed).
	â€¢	CLIP/LLM caption of tile contains required objects (doors, table).

â¸»

4. utils.py essentials (pseudo-code)

def build_prompt(camera, style_tokens, base, global_tokens=()):
    return (
      f"orthographic isometric {camera['angle_deg']}deg, "
      f"16-bit pixel art, {', '.join(style_tokens)}, "
      f"{base}. no perspective, no cast shadows, flat lighting, "
      f"crisp outlines, limited palette"
    )

def compose_base(context_tiles, target_rect, pad=8):
    # create large canvas; paste neighbors; crop (target_rect expanded by pad)
    # return PIL.Image

def blur_overlay(img, radius=2, alpha=0.30):
    # gaussian blur + white overlay alpha blend

def cacs_key(meta:dict, mask_bytes:bytes, base_bytes:bytes)->str: ...

def ssim(imgA, imgB, region=None)->float: ...


â¸»

5. provider adapters

Plan A (diffusers)

from diffusers import StableDiffusionInpaintPipeline, ControlNetModel
import torch, PIL.Image as Image, numpy as np

def load_pipe(model_id="stabilityai/stable-diffusion-xl-base-1.0",
              lora="nerijs/pixel-art-xl",
              controlnets=("lllyasviel/sd-controlnet-canny",),
              device="mps"):
    pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id)
    # attach ControlNets if requested
    # load LoRA weights
    pipe.to(device)
    return pipe

def inpaint(pipe, base:Image.Image, mask:Image.Image, prompt:str, seed:int):
    gen = torch.Generator(device=pipe.device).manual_seed(seed)
    out = pipe(prompt=prompt, image=base, mask_image=mask, generator=gen)
    return out.images[0]

Docs: inpaint API, pipelines, ControlNet.  ï¿¼
Pixel-Art XL LoRA note.  ï¿¼

Plan B (Leonardo)
	â€¢	Use REST API with sdxl inpaint engine and seed parameter.
	â€¢	If seam, run ring inpaint with local SD (Plan A) using same seed.

Plan C (OpenAI)
	â€¢	Generate base concept; determinism not guaranteed ([Unverified]). Immediately run Plan A ring inpaint for borders and widget masks.

â¸»

6. generation order (strict)
	â€¢	Floor1: generate navigation sequence leftâ†’right.
	â€¢	After each tile, run edge-blend guard with existing neighbors before moving on.
	â€¢	After all tiles on floor1, run widgets pass across floor1.
	â€¢	FloorN>1: build blurred placeholders (do not persist assets for viewer; used only here). Generate tiles with placeholder context, then widgets.
	â€¢	After a floor completes, persist floor_sprite.png (optional) as stitched debug.

Verify
	â€¢	Deleting any single overlays/<widget>_<state>.png and re-running regenerates only that overlay.
	â€¢	Deleting base.png for a location regenerates base and re-validates ring SSIM with neighbors.

â¸»

7. TDD and visual gates

Unit
	â€¢	Schema validator (world.json).
	â€¢	Cache CACS stable under same inputs.
	â€¢	Outside-mask invariance (mask complement exact match).

Visual
	â€¢	Border SSIM â‰¥ 0.98.
	â€¢	Per-tile CLIP similarity to text â‰¥ threshold.
	â€¢	LLM Vision judge (manual, not CI) returns â‰¥ 85/100 with rationale.

Playwright
	â€¢	Screenshot per floor after viewer build; diffs must be zero (mask dynamic text).

Docs: Playwright test snapshots/screenshots.  ï¿¼

â¸»

8. prompts hardening
	â€¢	Global style tokens fixed: "orthographic isometric 45deg, 16-bit pixel art, flat lighting, crisp outline, limited palette, Helsinki references minimal".
	â€¢	Negative tokens: "no perspective, no cast shadows, no photorealism, no gradient banding, no glow, no DOF".
	â€¢	Widgets: prompt patterns
	â€¢	idle: "render a [widget] placed exactly inside mask, consistent perspective and palette"
	â€¢	state: "change ONLY [widget] to [state], keep surroundings identical"

Verify
	â€¢	If semantic judge fails, prepend "strict: obey mask region and camera; do not alter outside area." and retry same seed.

â¸»

9. failure/repair macros
	â€¢	If border SSIM < 0.98 â†’ run ring_inpaint(mask=border8px, prompt="seamless continuity").
	â€¢	If style drift â†’ increase ControlNet weight; add "flat dithering"; or switch scheduler DDIMâ†’DPM++.
	â€¢	If repeated failure on Plan A â†’ Plan B. If Plan B fails â†’ Plan C then ring_inpaint.

Docs: ControlNet multi-conditioning.  ï¿¼

â¸»

10. synCity alignment notes
	â€¢	Tile-in-context, mask-only changes, fixed camera, neighbor-aware blending are directly aligned with SynCity methodology and public repo statements.  ï¿¼

â¸»

DOD (tiles)
	â€¢	All location base.png produced deterministically (Plan A).
	â€¢	All widget overlays produced; outside-mask pixels identical to base.
	â€¢	Border SSIM checks pass.
	â€¢	Metadata JSON emitted per output.
	â€¢	Cache hit/miss works; partial deletions regenerate minimal scope.
	â€¢	Visual e2e screenshots stable.

DOR (tiles)
	â€¢	world.json validated.
	â€¢	Models reachable with API keys.
	â€¢	Pixel-Art XL LoRA present (Plan A).  ï¿¼
	â€¢	ControlNet canny/depth ready.  ï¿¼

â¸»

pre-release checklist (viewer + tiles)
	â€¢	Rebuild full site (viewer_builder.py, then world_generator.py).
	â€¢	Lighthouse SEO/A11y â‰¥ 90.
	â€¢	Playwright screenshots equal to baselines.
	â€¢	Manual LLM-vision judge â‰¥ 85/100 with reasoning.
	â€¢	Audio loads and can be muted; credits present.
	â€¢	sitemap.xml and robots.txt valid.

post-release checklist
	â€¢	Submit sitemap to Search Console.
	â€¢	Monitor broken links and image 404s.
	â€¢	Regenerate on content changes; verify determinism.
	â€¢	Rotate ambient track if needed; keep same author/library for timbre coherence.

â¸»

Notes on licenses and attributions
	â€¢	Pixabay tracks and SFX listed are under the Pixabay Content License (free for commercial use; attribution not required; recommended). Confirm on each asset page before use.  ï¿¼

References
	â€¢	SynCity paper/site/repo.  ï¿¼
	â€¢	Diffusers inpaint + pipelines.  ï¿¼
	â€¢	ControlNet docs and models.  ï¿¼
	â€¢	Pixel-Art XL LoRA.  ï¿¼
	â€¢	MDN prefers-reduced-motion.  ï¿¼
	â€¢	Playwright snapshots/screenshots.  ï¿¼
	â€¢	Accessible modal guidance.  ï¿¼
	â€¢	Pixabay lofi library.

If you want me to apply this into /PRPs/PRP-016.md or scaffold the files, say â€œapply patch to repo PRP-016â€ and I will write the edits.
