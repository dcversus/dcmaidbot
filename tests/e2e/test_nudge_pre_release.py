#!/usr/bin/env python3
"""
E2E Tests: Nudge Pre-Release System
==================================

Tests the /nudge endpoint for pre-release and post-release notifications
as specified in AGENTS.md requirements.
"""

import os
import time

import psutil
import pytest
import requests


# Performance tracking
class PerformanceTracker:
    """Track response time and memory usage for /nudge API calls."""

    def __init__(self):
        self.start_time = None
        self.start_memory = None
        self.end_memory = None
        self.response_time = None
        self.memory_increase = None

    def start_tracking(self):
        """Start tracking performance metrics."""
        self.start_time = time.time()
        self.start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB

    def end_tracking(self):
        """End tracking and calculate metrics."""
        self.end_time = time.time()
        self.end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        self.response_time = (self.end_time - self.start_time) * 1000  # ms
        self.memory_increase = self.end_memory - self.start_memory  # MB
        return self

    def get_metrics(self):
        """Get performance metrics as dictionary."""
        return {
            "response_time_ms": self.response_time,
            "memory_usage_mb": self.end_memory,
            "memory_increase_mb": self.memory_increase,
            "start_memory_mb": self.start_memory,
            "end_memory_mb": self.end_memory,
        }


def call_nudge_api(
    base_url: str,
    secret: str,
    message: str,
    nudge_type: str = "direct",
    user_id: int = None,
    performance_tracker: PerformanceTracker = None,
) -> dict:
    """Make HTTP request to /nudge endpoint with optional performance tracking.

    Args:
        base_url: Base URL for the API
        secret: NUDGE_SECRET for authentication
        message: Message to send
        nudge_type: Type of nudge ("direct" or "llm")
        user_id: Optional specific user ID
        performance_tracker: Optional PerformanceTracker for metrics

    Returns:
        dict: Response from /nudge endpoint
    """
    headers = {
        "Authorization": f"Bearer {secret}",
        "Content-Type": "application/json",
    }

    data = {
        "message": message,
        "type": nudge_type,
    }

    if user_id:
        data["user_id"] = user_id

    if performance_tracker:
        performance_tracker.start_tracking()

    response = requests.post(f"{base_url}/nudge", headers=headers, json=data)

    if performance_tracker:
        performance_tracker.end_tracking()

    return response


class TestNudgePreRelease:
    """Test nudge pre-release and post-release functionality"""

    @pytest.fixture
    def nudge_config(self):
        """Get nudge configuration from environment"""
        return {
            "secret": os.getenv("NUDGE_SECRET"),
            "base_url": "https://dcmaidbot.theedgestory.org",
            "vasilisa_id": int(os.getenv("VASILISA_TG_ID", "122657093")),
            "admin_ids": [
                int(x) for x in os.getenv("ADMIN_IDS", "").split(",") if x.strip()
            ],
        }

    def test_nudge_authentication(self, nudge_config):
        """Test nudge endpoint authentication with valid and invalid tokens"""
        base_url = nudge_config["base_url"]
        valid_secret = nudge_config["secret"]

        # Performance tracking setup
        performance_tracker = PerformanceTracker()

        # Test with valid token
        response = call_nudge_api(
            base_url=base_url,
            secret=valid_secret,
            message="Test message for authentication",
            nudge_type="direct",
            user_id=nudge_config["vasilisa_id"],
            performance_tracker=performance_tracker,
        )

        assert response.status_code == 200, f"Valid token should work: {response.text}"
        assert response.json()["status"] == "success"

        # Validate performance metrics for valid authentication
        metrics = performance_tracker.get_metrics()
        print("\nðŸ“Š Valid Authentication Performance:")
        print(f"  Response time: {metrics['response_time_ms']:.2f}ms")
        print(f"  Memory usage: {metrics['memory_usage_mb']:.2f}MB")
        print(f"  Memory increase: {metrics['memory_increase_mb']:.2f}MB")

        # Performance assertions for authentication
        assert metrics["response_time_ms"] < 5000, (
            f"Authentication response too slow: {metrics['response_time_ms']}ms"
        )
        assert metrics["memory_increase_mb"] < 25, (
            f"Memory increase too high for auth: {metrics['memory_increase_mb']}MB"
        )

        # Test with invalid token
        response = call_nudge_api(
            base_url=base_url,
            secret="invalid_token",
            message="Test message",
            nudge_type="direct",
        )

        assert response.status_code == 401, "Invalid token should be unauthorized"
        assert "Invalid authorization token" in response.json()["error"]

        # Test with no token (using requests directly since we need to test missing auth header)
        response = requests.post(
            f"{base_url}/nudge",
            headers={"Content-Type": "application/json"},
            json={"message": "Test message", "type": "direct"},
        )

        assert response.status_code == 401, "No token should be unauthorized"

    def test_nudge_pre_release_to_vasilisa(self, nudge_config):
        """Test sending pre-release notification to Vasilisa specifically"""
        base_url = nudge_config["base_url"]
        vasilisa_id = nudge_config["vasilisa_id"]

        # Performance tracking setup
        performance_tracker = PerformanceTracker()

        pre_release_message = f"""ðŸš¨ **PRE-RELEASE WARNING** ðŸš¨

**Release**: Advanced UI Behaviors - v0.1.1
**Target User**: Vasilisa (ID: {vasilisa_id})
**Timestamp**: {pytest.__version__}

### ðŸ“‹ Pre-Release Checklist Status:
- [x] Hover State Isolation - **PASSING** âœ…
- [x] Modal Color Contrast - **PASSING** âœ… (100% dark text)
- [x] Modal Transparency - **WORKING** âœ… (0.1% white background)
- [x] 16-bit Movement Graphics - **DETECTED** âœ…
- [x] Screenshot Comparison - **TEST READY** âœ…

### ðŸŽ¯ **Ready for Review**:
All critical user requirements implemented and tested. Please review the advanced UI behavior improvements.

**Test Coverage**: 4/4 E2E tests created and validated
**User Requirements**: Dark text on transparent backgrounds âœ…
**Hover Isolation**: Per-widget state changes working âœ…

*This is an automated pre-release notification. Review and provide feedback before production deployment.*"""

        response = call_nudge_api(
            base_url=base_url,
            secret=nudge_config["secret"],
            message=pre_release_message,
            nudge_type="direct",
            user_id=vasilisa_id,
            performance_tracker=performance_tracker,
        )

        assert response.status_code == 200, (
            f"Pre-release nudge should succeed: {response.text}"
        )

        result = response.json()
        assert result["status"] == "success"
        assert result["message"] == "Message sent via direct mode"
        assert result["result"]["sent_count"] == 1
        assert result["result"]["failed_count"] == 0

        # Validate performance metrics for pre-release notification
        metrics = performance_tracker.get_metrics()
        print("\nðŸ“Š Pre-Release Notification Performance:")
        print(f"  Response time: {metrics['response_time_ms']:.2f}ms")
        print(f"  Memory usage: {metrics['memory_usage_mb']:.2f}MB")
        print(f"  Memory increase: {metrics['memory_increase_mb']:.2f}MB")

        # Performance assertions for pre-release notification (should be reasonable for large messages)
        assert metrics["response_time_ms"] < 10000, (
            f"Pre-release notification too slow: {metrics['response_time_ms']}ms"
        )
        assert metrics["memory_increase_mb"] < 50, (
            f"Memory increase too high for pre-release: {metrics['memory_increase_mb']}MB"
        )

        # Verify the specific user was targeted
        sent_results = result["result"]["results"]
        assert len(sent_results) == 1
        assert sent_results[0]["user_id"] == vasilisa_id
        assert sent_results[0]["status"] == "success"
        assert "message_id" in sent_results[0]

        print(f"âœ… Pre-release nudge sent successfully to Vasilisa (ID: {vasilisa_id})")
        print(f"   Message ID: {sent_results[0]['message_id']}")

    def test_nudge_post_release_to_all_admins(self, nudge_config):
        """Test sending post-release notification to all admins with changelog"""
        base_url = nudge_config["base_url"]
        admin_ids = nudge_config["admin_ids"]

        # Performance tracking setup
        performance_tracker = PerformanceTracker()

        # Simulate changelog content (in real scenario, this would come from CHANGELOG.md)
        changelog_content = """# ðŸŽ‰ Advanced UI Behaviors - v0.1.1

## âœ¨ What's New

### ðŸŽ¨ **Advanced UI Behavior Requirements**
- **Hover State Isolation**: Hover only affects specific widget area, not other elements
- **Modal Color Contrast**: Dark text on transparent backgrounds for accessibility
- **Widget Background States**: Each widget has pre-generated background for modal interactions
- **Screenshot Comparison**: Modal states show â‰¥5% visual difference
- **16-bit Movement Graphics**: Pixel-perfect movement animations

### ðŸ”§ **Critical Fixes Completed**
- âœ… **Loading Infinity Fixed**: All missing files copied and accessible
- âœ… **Modal Text Colors**: Changed from light gray (#cccccc) to dark (#333333)
- âœ… **Modal Transparency**: 0.1% white background as requested
- âœ… **E2E Test Framework**: Comprehensive tests for all advanced behaviors

### ðŸ“Š **Test Results Summary**
- **Modal Color Contrast**: âœ… **PASSING** (100% dark text achieved)
- **Hover State Isolation**: âœ… Working correctly
- **Advanced E2E Tests**: 4/4 tests created and validated
- **User Requirements**: 100% met and verified

### ðŸš€ **Deployment Details**
- **Deployed to**: Production (dcmaidbot.theedgestory.org)
- **Docker Image**: dcmaidbot:latest-v0.1.1
- **Kubernetes**: All pods healthy and serving traffic
- **Rollout Status**: Complete (100% of pods updated)

### ðŸ“‹ **E2E Test Results**
```bash
âœ… test_hover_state_isolation_only_widget_area - PASS
âœ… test_modal_color_contrast_dark_text_on_transparent_bg - PASS
âœ… test_widget_specific_modal_background_states - PASS
âœ… test_screenshot_comparison_modal_states - PASS
```

**All critical user requirements implemented and tested successfully!** ðŸŽ¯"""

        post_release_message = f"""ðŸŽ‰ **RELEASE DEPLOYED SUCCESSFULLY** ðŸŽ‰

**Version**: Advanced UI Behaviors - v0.1.1
**Status**: âœ… **PRODUCTION LIVE**
**Timestamp**: {pytest.__version__}

---

{changelog_content}

---

ðŸ”— **Live Demo**: https://dcmaidbot.theedgestory.org
ðŸ“Š **Health Check**: https://dcmaidbot.theedgestory.org/health
ðŸ“‹ **Changelog**: https://dcmaidbot.theedgestory.org/changelog

*Automated post-release notification sent to all administrators*"""

        response = call_nudge_api(
            base_url=base_url,
            secret=nudge_config["secret"],
            message=post_release_message,
            nudge_type="direct",
            performance_tracker=performance_tracker,
            # No user_id specified = send to all admins
        )

        assert response.status_code == 200, (
            f"Post-release nudge should succeed: {response.text}"
        )

        result = response.json()
        assert result["status"] == "success"
        assert result["message"] == "Message sent via direct mode"

        # Validate performance metrics for post-release notification
        metrics = performance_tracker.get_metrics()
        print("\nðŸ“Š Post-Release Notification Performance:")
        print(f"  Response time: {metrics['response_time_ms']:.2f}ms")
        print(f"  Memory usage: {metrics['memory_usage_mb']:.2f}MB")
        print(f"  Memory increase: {metrics['memory_increase_mb']:.2f}MB")

        # Performance assertions for post-release notification (bulk messaging to multiple admins)
        assert metrics["response_time_ms"] < 15000, (
            f"Post-release notification too slow: {metrics['response_time_ms']}ms"
        )
        assert metrics["memory_increase_mb"] < 75, (
            f"Memory increase too high for post-release: {metrics['memory_increase_mb']}MB"
        )

        # Verify message was sent to all admins
        assert result["result"]["sent_count"] == len(admin_ids)
        assert result["result"]["failed_count"] == 0

        sent_results = result["result"]["results"]
        assert len(sent_results) == len(admin_ids)

        # Check each admin received the message
        for i, admin_id in enumerate(admin_ids):
            assert sent_results[i]["user_id"] == admin_id
            assert sent_results[i]["status"] == "success"
            assert "message_id" in sent_results[i]

        print(f"âœ… Post-release nudge sent successfully to {len(admin_ids)} admins")
        print(f"   Admin IDs: {admin_ids}")

    def test_nudge_llm_mode(self, nudge_config):
        """Test nudge LLM mode for personalized messages"""
        base_url = nudge_config["base_url"]

        # Performance tracking setup
        performance_tracker = PerformanceTracker()

        llm_message = "Hi Vasilisa! I've completed the advanced UI behavior improvements. The modal now has dark text on transparent backgrounds as you requested, and I've created comprehensive E2E tests to validate everything. Could you please review the changes when you have a moment?"

        response = call_nudge_api(
            base_url=base_url,
            secret=nudge_config["secret"],
            message=llm_message,
            nudge_type="llm",
            user_id=nudge_config["vasilisa_id"],
            performance_tracker=performance_tracker,
        )

        assert response.status_code == 200, (
            f"LLM mode nudge should succeed: {response.text}"
        )

        result = response.json()
        assert result["status"] == "success"
        assert result["message"] == "Message sent via llm mode"
        assert result["result"]["sent_count"] == 1

        # Validate performance metrics for LLM mode
        metrics = performance_tracker.get_metrics()
        print("\nðŸ“Š LLM Mode Performance:")
        print(f"  Response time: {metrics['response_time_ms']:.2f}ms")
        print(f"  Memory usage: {metrics['memory_usage_mb']:.2f}MB")
        print(f"  Memory increase: {metrics['memory_increase_mb']:.2f}MB")

        # Performance assertions for LLM mode (should be slower due to LLM processing, but reasonable)
        assert metrics["response_time_ms"] < 20000, (
            f"LLM mode response too slow: {metrics['response_time_ms']}ms"
        )
        assert metrics["memory_increase_mb"] < 100, (
            f"Memory increase too high for LLM mode: {metrics['memory_increase_mb']}MB"
        )

        print("âœ… LLM mode nudge sent successfully")
        print(f"   Mode: {result['result']['mode']}")
        print(f"   Message ID: {result['result']['results'][0]['message_id']}")

    def test_nudge_error_handling(self, nudge_config):
        """Test nudge endpoint error handling for invalid requests"""
        base_url = nudge_config["base_url"]

        # Performance tracking for error cases
        validation_error_tracker = PerformanceTracker()

        # Test missing required fields
        response = call_nudge_api(
            base_url=base_url,
            secret=nudge_config["secret"],
            message="",
            nudge_type="direct",
            performance_tracker=validation_error_tracker,
        )

        assert response.status_code == 400, "Missing fields should return 400"
        assert "Missing or invalid field: message" in response.json()["error"]

        # Validate performance for validation error
        validation_metrics = validation_error_tracker.get_metrics()
        print("\nðŸ“Š Validation Error Performance:")
        print(f"  Response time: {validation_metrics['response_time_ms']:.2f}ms")
        assert validation_metrics["response_time_ms"] < 1000, (
            f"Validation error response too slow: {validation_metrics['response_time_ms']}ms"
        )

        # Test invalid type
        response = call_nudge_api(
            base_url=base_url,
            secret=nudge_config["secret"],
            message="Test message",
            nudge_type="invalid_type",
        )

        assert response.status_code == 400, "Invalid type should return 400"
        assert "Missing or invalid field: type" in response.json()["error"]

        # Test invalid user_id
        response = requests.post(
            f"{base_url}/nudge",
            headers={
                "Authorization": f"Bearer {nudge_config['secret']}",
                "Content-Type": "application/json",
            },
            json={"message": "Test message", "type": "direct", "user_id": "invalid_id"},
        )

        assert response.status_code == 400, "Invalid user_id should return 400"
        assert "Invalid field: user_id" in response.json()["error"]

        print("âœ… Error handling tests passed")


if __name__ == "__main__":
    pytest.main([__file__])
